
RUN 2 (completed) — Summary for future writeup
=============================================

Run number: 2
Dataset: ag_news (HuggingFace Datasets)
Task framing: "5-way action classification proxy" to emulate an agent decision policy for a verifier-driven
decomposition/localization workflow.

Actions (5 classes, fixed order):
  0 LocalPatch
  1 TargetedRegenerate
  2 RefineDecomposition
  3 ContractUpdate
  4 WholeRepoRegenerate

Deterministic label mapping from AG News:
  - World -> LocalPatch
  - Sports -> TargetedRegenerate
  - Business -> RefineDecomposition
  - Sci/Tech -> split deterministically into (ContractUpdate vs WholeRepoRegenerate) using a stable hash parity of the text.

Motivation for this mapping:
  We need 5 classes but AG News has 4 topics. Splitting Sci/Tech deterministically avoids randomness and creates
  a controlled extra action class while preserving a text signal.

Split protocol and sizes:
  - Total pool: first 9000 samples from ag_news train split.
  - Stratified split into train/val/test with fixed random_state for determinism.
  - Sizes: train=5000, val=2000, test=2000.

Observed class distributions:
  - train: [1250, 1250, 1250, 625, 625]
  - val:   [ 500,  500,  500, 250, 250]
  - test:  [ 500,  500,  500, 250, 250]
This addressed Run 1 issues (perfect accuracy with some classes having zero support), suggesting Run 1 had
label/split leakage or missing classes in splits.

Model:
  - TF-IDF (max_features=1500, ngrams=1..2) -> 2-layer MLP (hidden_dim=64, dropout=0.2) -> 5-way logits
  - Optimizer: AdamW(lr=1e-3, weight_decay=1e-4), epochs=6, CPU
  - Parameter count: 96,389

Training stats (loss):
  - Train loss by epoch: [1.5029, 1.0759, 0.7399, 0.5963, 0.5238, 0.4753]
  - Val loss: 0.5954

Validation metrics:
  - Accuracy: 0.756
  - Macro-F1: 0.65493
  - ECE (10 bins): 0.03472
  - Confusion matrix (rows=true, cols=pred):
    [[430, 29, 26,  2, 13],
     [  9,474, 13,  0,  4],
     [ 24, 15,429,  6, 26],
     [ 16, 13, 32, 28,161],
     [ 17,  7, 43, 32,151]]
  - Focused confusion (ContractUpdate vs TargetedRegenerate):
      contractupdate_as_targetedregenerate: 13 (out of 250 ContractUpdate)
      targetedregenerate_as_contractupdate: 0 (out of 500 TargetedRegenerate)
    Major confusion issue is ContractUpdate vs WholeRepoRegenerate, consistent with being a deterministic split
    of Sci/Tech.

Test metrics:
  - Accuracy: 0.7595
  - Macro-F1: 0.66279
  - ECE (10 bins): 0.02856
  - Confusion matrix:
    [[440, 19, 32,  0,  9],
     [ 16,473,  8,  1,  2],
     [ 24, 10,422,  5, 39],
     [ 29, 12, 33, 34,142],
     [ 24, 12, 30, 34,150]]

Downstream proxy "agent loop" metrics (computed from predicted probabilities):
  - regeneration_scope = P(TargetedRegenerate) + 2*P(WholeRepoRegenerate)
  - files_touched = 1 + 4.5*regen_scope
  - pass@budget: per-item p_success = 0.5 + 0.5*max_prob, assume 30 independent tries
  - Observed: pass_at_budget_expected=1.0, mean_files_touched≈3.293, budget_iters=30

Artifacts:
  - TF-IDF vocab size: 1500

Key takeaways:
  - Removing split/label issues fixed unrealistic perfect accuracy.
  - Model performs reasonably (~0.76 accuracy) but has notable confusion between the two Sci/Tech-derived action
    labels (ContractUpdate vs WholeRepoRegenerate), limiting macro-F1.
  - Calibration error is already low, but downstream loop metrics strongly depend on max probability and thus are
    sensitive to calibration; improving calibration may stabilize agent-policy proxies.

Next planned step (for Run 3):
  Add post-hoc temperature scaling on the validation set to improve calibration (ECE/NLL) while keeping accuracy
  unchanged (argmax invariant under positive temperature). Report metrics before/after calibration and evaluate
  downstream proxy metrics using calibrated probabilities.

